{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a899a4",
   "metadata": {},
   "source": [
    "# Getting Data About Dengue Across Brazil\n",
    "\n",
    "To begin the data collection, the **SINAN Portal** was chosen as the most reliable source of information for **Epidemiological Surveillance in general**.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick description about SINAN\n",
    "\n",
    "The **Notifiable Diseases Information System (SINAN)** aims to collect, transmit, and disseminate data routinely generated by epidemiological surveillance at all three levels of government through a computerized network. This system supports investigation processes and provides input for the analysis of information on diseases and health problems subject to mandatory reporting.  \n",
    "\n",
    "Currently, the system operates in two active versions: **SINAN Online** and **SINAN Net**.\n",
    "\n",
    "**Access to the 'Dengue' dataset on the openDataSUS Portal:**  \n",
    "ðŸ‘‰ [https://opendatasus.saude.gov.br/dataset/arboviroses-dengue](https://opendatasus.saude.gov.br/dataset/arboviroses-dengue)\n",
    "\n",
    "---\n",
    "\n",
    "### Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b236b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os              # For file and directory operations\n",
    "import requests        # For downloading files from the internet\n",
    "import zipfile         # For handling ZIP files\n",
    "import shutil          # For high-level file operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c11d3",
   "metadata": {},
   "source": [
    "### Defining Headers and Paths\n",
    "\n",
    "To avoid being blocked by the server, we define a HEADERS dictionary that mimics a standard browser request.\n",
    "\n",
    "Then, we set the base URL for the SINAN dengue dataset and specify where the raw data will be stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd6abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Https headers to mimic a browser visit - avoid potential blocking by server\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "}\n",
    "\n",
    "BASE_URL = 'https://s3.sa-east-1.amazonaws.com/ckan.saude.gov.br/SINAN/Dengue/csv/'\n",
    "RAW_DIR = '../data/raw/dengue'\n",
    "\n",
    "RAW_FILES = [\n",
    "    'DENGBR24.csv',\n",
    "    'DENGBR23.csv',\n",
    "    'DENGBR22.csv',\n",
    "    'DENGBR21.csv',\n",
    "    'DENGBR20.csv',\n",
    "    'DENGBR19.csv',\n",
    "    'DENGBR18.csv',\n",
    "    'DENGBR17.csv',\n",
    "    'DENGBR16.csv',\n",
    "    'DENGBR15.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e97fe",
   "metadata": {},
   "source": [
    "---\n",
    "### Automating the Data Collection\n",
    "\n",
    "The approach used here automates the process of downloading, extracting, and organizing dengue case datasets from the official repository.\n",
    "\n",
    "Each `.zip` file is downloaded, uncompressed, and its corresponding `.csv` file is moved to the raw data directory for further processing.\n",
    "Temporary files and directories are removed automatically to keep the workspace clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFile(url: str, local_path: str):\n",
    "    r = requests.get(url, headers=HEADERS, stream=True)  # stream=True to download large files\n",
    "    try:\n",
    "        r.raise_for_status()\n",
    "        with open(local_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    finally:\n",
    "        r.close()\n",
    "\n",
    "def extractFile(zip_path: str, extract_dir: str):\n",
    "    try: \n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir) \n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"  -> ERRO: O arquivo baixado estÃ¡ corrompido ou Ã© um ZIP invÃ¡lido.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  -> ERRO durante a extraÃ§Ã£o: {e}\")\n",
    "\n",
    "def moveFileCSV(base_path: str, final_filename: str):\n",
    "    extracted_csv_name = None\n",
    "    for item in os.listdir(base_path):\n",
    "        if item.endswith('.csv'):\n",
    "            extracted_csv_name = item\n",
    "            break\n",
    "            \n",
    "    if extracted_csv_name:\n",
    "        source = os.path.join(base_path, extracted_csv_name)\n",
    "        destination = os.path.join(RAW_DIR, final_filename) \n",
    "        \n",
    "        shutil.move(source, destination)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e95ad",
   "metadata": {},
   "source": [
    "Now we loop through all the files we need â€” from 2015 to 2024 â€” and apply the functions defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d51d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in RAW_FILES:\n",
    "    DOWNLOAD_FILE_NAME = BASE_URL + file + '.zip'\n",
    "    ZIP_FILE_PATH = os.path.join(RAW_DIR, file + '.zip')\n",
    "    TEMP_EXTRACT_PATH = os.path.join(RAW_DIR, file.replace('.csv', ''))\n",
    "\n",
    "    try:\n",
    "        downloadFile(DOWNLOAD_FILE_NAME, local_path=ZIP_FILE_PATH)\n",
    "        extractFile(ZIP_FILE_PATH, extract_dir=TEMP_EXTRACT_PATH)\n",
    "        moveFileCSV(base_path=TEMP_EXTRACT_PATH, final_filename=file)\n",
    "\n",
    "        shutil.rmtree(TEMP_EXTRACT_PATH) \n",
    "        os.remove(ZIP_FILE_PATH)\n",
    "\n",
    "    except requests.exceptions.HTTPError as e: \n",
    "        print(f\"ERRO HTTP ao baixar {file}: Verifique a URL ou a disponibilidade. Erro: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO inesperado no processamento de {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97691e5d",
   "metadata": {},
   "source": [
    "---\n",
    "### Directory Structure\n",
    "\n",
    "After successful execution, the directory structure will be organized as expected.\n",
    "All .csv files from the last 10 years will be available under ../data/raw/dengue:\n",
    "\n",
    "In the end, the dir structure will be exactly as expected. All the files .csv over the last 10 years are now downloaded in '../data/raw/dengue' this way..."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca5a9592",
   "metadata": {},
   "source": [
    "DengueCaboFrio-DataAnalysis/\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ raw/\n",
    "â”‚   â”‚   â””â”€â”€ dengue/\n",
    "â”‚   â”‚       â”œâ”€â”€ DENGBR15.csv\n",
    "â”‚   â”‚       â”œâ”€â”€ DENGBR16.csv\n",
    "â”‚   â”‚       â”œâ”€â”€ DENGBR17.csv\n",
    "â”‚   â”‚       â”œâ”€â”€ DENGBR18.csv\n",
    "â”‚   â”‚       â”œâ”€â”€ DENGBR19.csv\n",
    "â”‚   â”‚       â”œâ”€â”€ DENGBR20.csv\n",
    "â”‚   â”‚       â”œâ”€â”€ DENGBR21.csv\n",
    "â”‚   â”‚       â”œâ”€â”€ DENGBR22.csv\n",
    "â”‚   â”‚       â”œâ”€â”€ DENGBR23.csv\n",
    "â”‚   â”‚       â””â”€â”€ DENGBR24.csv\n",
    "â”‚   â””â”€â”€ processed/\n",
    "â”‚       â””â”€â”€ dengue/\n",
    "â”œâ”€â”€ notebooks/\n",
    "â””â”€â”€ README.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
